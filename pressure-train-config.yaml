data:
  dataset:
    name: pressure1 # choices are ['pressure1', 'pressure2', 'pressure3', 'pressure4']
    root_path: /home/lab-wu.shibin/dann/data/pressure1 # /path/to/dataset/root
    source: 0 # source domain index
    target: 1 # target domain index
    

  dataloader:
    data_workers: 4 # how many workers to use for train dataloaders
    batch_size: 12 # batch_size for source domain and target domain respectively

model:
  base_model: resnet50 # choices=['resnet50', 'vgg16']
  pretrained_model: # /path/to/pretrained/model
  bottle_neck_dim: 2048
  source_subject_no: #number of sub-dataset in Source Domain, which depends on your own settings

train:
  min_step: 100 # minimum steps to run. run epochs until it exceeds the minStep
  lr: 0.001 # learning rate for new layers. learning rate for finetune is 1/10 of lr， choices=[0.01， 0.001]
  weight_decay: 0.002 # choices=[0.0005， 0.001, 0.002]
  momentum: 0.95
  SF_weight: 1
  DA_weight: 1
  num_class: 1

test:
  test_interval: 2 # interval of two continuous test phase
  test_only: False # test a given model and exit
  resume_file: '' # model to test

misc:
  gpus: 1 # how many GPUs to be used, 0 indicates CPU only

log:
  root_dir: log # the log directory (log directory will be {root_dir}/{method}/time/)
  log_interval: 100 # steps to log scalars
